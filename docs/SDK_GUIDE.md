# NeuroMemory 使用指南

> **Python 版本**: 3.10+
> **最后更新**: 2026-02-11

---

## 目录

1. [安装](#1-安装)
2. [初始化](#2-初始化)
3. [语义记忆](#3-语义记忆)
4. [KV 存储](#4-kv-存储)
5. [对话管理](#5-对话管理)
6. [文件管理](#6-文件管理)
7. [图数据库](#7-图数据库)
8. [记忆提取](#8-记忆提取)
9. [时间查询](#9-时间查询)
10. [错误处理](#10-错误处理)
11. [自定义 Provider](#11-自定义-provider)

---

## 1. 安装

```bash
# 核心依赖
pip install -e .

# 全部可选依赖
pip install -e ".[all]"
```

依赖 PostgreSQL（含 pgvector）：
```bash
docker compose -f docker-compose.yml up -d db
```

---

## 2. 初始化

### 2.1 基础初始化

```python
from neuromemory import NeuroMemory, SiliconFlowEmbedding

nm = NeuroMemory(
    database_url="postgresql+asyncpg://neuromemory:neuromemory@localhost:5432/neuromemory",
    embedding=SiliconFlowEmbedding(api_key="your-key"),
)
await nm.init()   # 创建表、初始化扩展

# 使用...

await nm.close()  # 关闭连接池
```

### 2.2 上下文管理器（推荐）

```python
async with NeuroMemory(
    database_url="postgresql+asyncpg://...",
    embedding=SiliconFlowEmbedding(api_key="..."),
) as nm:
    await nm.add_memory(user_id="alice", content="Hello")
    # 自动调用 init() 和 close()
```

### 2.3 完整配置

```python
from neuromemory import (
    NeuroMemory,
    SiliconFlowEmbedding,
    OpenAILLM,
    S3Storage,
)

nm = NeuroMemory(
    database_url="postgresql+asyncpg://user:pass@host:5432/db",
    embedding=SiliconFlowEmbedding(api_key="..."),
    llm=OpenAILLM(                          # 可选：记忆提取
        api_key="...",
        model="deepseek-chat",
        base_url="https://api.deepseek.com/v1",
    ),
    storage=S3Storage(                       # 可选：文件存储
        endpoint="http://localhost:9000",
        access_key="neuromemory",
        secret_key="neuromemory123",
        bucket="neuromemory",
    ),
    pool_size=20,                            # 数据库连接池大小
)
```

### 2.4 参数说明

| 参数 | 类型 | 必填 | 说明 |
|------|------|------|------|
| database_url | str | 是 | PostgreSQL 连接字符串 |
| embedding | EmbeddingProvider | 是 | Embedding 服务 |
| llm | LLMProvider | 否 | LLM 服务（记忆提取需要） |
| storage | ObjectStorage | 否 | 文件存储（文件功能需要） |
| pool_size | int | 否 | 连接池大小（默认 10） |

---

## 3. 语义记忆

### 3.1 添加记忆

```python
# 基础用法
embedding = await nm.add_memory(
    user_id="alice",
    content="I work at ABC Company as a software engineer",
)

# 带类型和元数据
embedding = await nm.add_memory(
    user_id="alice",
    content="Attended team meeting on project planning",
    memory_type="episodic",
    metadata={"date": "2026-02-10", "participants": ["bob"]},
)
```

记忆类型建议：

| 类型 | 说明 | 示例 |
|------|------|------|
| `fact` | 事实性知识 | "Python 是一种编程语言" |
| `episodic` | 事件记录 | "昨天参加了项目会议" |
| `preference` | 用户偏好 | "我喜欢喝咖啡" |
| `document` | 文档内容 | 自动从文件提取 |
| `general` | 通用（默认） | 其他 |

### 3.2 语义检索

```python
# 基础检索
results = await nm.search(
    user_id="alice",
    query="Where does Alice work?",
)

# 带过滤
results = await nm.search(
    user_id="alice",
    query="meetings",
    memory_type="episodic",
    limit=20,
)

# 结果格式
for r in results:
    print(f"[{r['similarity']:.2f}] {r['content']}")
    # r['id'], r['memory_type'], r['metadata'], r['created_at']
```

---

## 4. KV 存储

通用键值存储，按 `namespace + scope_id + key` 隔离。

### 4.1 基础 CRUD

```python
# 设置（支持任意 JSON 值）
await nm.kv.set("alice", "preferences", "language", "zh-CN")
await nm.kv.set("alice", "preferences", "theme", {"mode": "dark"})
await nm.kv.set("global", "settings", "max_tokens", 4096)

# 获取
value = await nm.kv.get("alice", "preferences", "language")
# 返回 "zh-CN"，不存在返回 None

# 删除
deleted = await nm.kv.delete("alice", "preferences", "language")
# 返回 True/False
```

### 4.2 列出和批量操作

```python
# 列出 namespace + scope 下所有键值
items = await nm.kv.list("alice", "preferences")
for item in items:
    print(f"{item.key}: {item.value}")

# 按前缀过滤
items = await nm.kv.list("alice", "preferences", prefix="theme")

# 批量设置
await nm.kv.batch_set("alice", "preferences", {
    "language": "zh-CN",
    "theme": {"mode": "dark"},
    "font_size": 14,
})
```

---

## 5. 对话管理

### 5.1 添加消息

```python
# 单条消息（自动生成 session_id）
msg = await nm.conversations.add_message(
    user_id="alice",
    role="user",
    content="Hello!",
)
print(msg.session_id)  # session_xxxx

# 指定 session
msg = await nm.conversations.add_message(
    user_id="alice",
    role="assistant",
    content="Hi! How can I help?",
    session_id="my_session_001",
)
```

### 5.2 批量添加

```python
session_id, message_ids = await nm.conversations.add_messages_batch(
    user_id="alice",
    messages=[
        {"role": "user", "content": "What's the weather?"},
        {"role": "assistant", "content": "It's sunny today!"},
        {"role": "user", "content": "Great, thanks!"},
    ],
    session_id="weather_chat",
)
```

### 5.3 查询

```python
# 获取会话历史
messages = await nm.conversations.get_history(
    user_id="alice",
    session_id="my_session_001",
    limit=50,
)

# 列出所有会话
total, sessions = await nm.conversations.list_sessions(
    user_id="alice",
    limit=20,
)
for s in sessions:
    print(f"Session {s.session_id}: {s.message_count} messages")
```

---

## 6. 文件管理

需要配置 `S3Storage`。

### 6.1 上传文件

```python
# 上传文件（自动提取文本 + 生成 embedding）
doc = await nm.files.upload(
    user_id="alice",
    filename="report.pdf",
    file_data=open("report.pdf", "rb").read(),
    category="work",
    tags=["quarterly", "finance"],
    auto_extract=True,  # 默认 True
)

print(f"ID: {doc.id}")
print(f"Extracted: {len(doc.extracted_text or '')} chars")
```

### 6.2 从文本创建文档

```python
doc = await nm.files.create_from_text(
    user_id="alice",
    title="Meeting Notes",
    content="Today we discussed the Q1 roadmap...",
    category="notes",
)
```

### 6.3 查询和删除

```python
# 列出文件
docs = await nm.files.list_documents(
    user_id="alice",
    category="work",
    file_types=["pdf", "docx"],
)

# 获取单个文件
doc = await nm.files.get_document(file_id=some_uuid)

# 删除文件（同时删除存储和数据库记录）
await nm.files.delete(file_id=some_uuid)
```

### 6.4 支持的文件类型

| 类型 | 扩展名 | 文本提取 |
|------|--------|---------|
| 文本 | .txt, .md, .json, .yaml, .csv, .html, .xml | 直接读取 |
| 代码 | .py, .js, .ts, .java, .go, .sql, .sh | 直接读取 |
| PDF | .pdf | pypdf |
| Word | .docx | python-docx |
| 图片 | .png, .jpg, .gif, .webp | 仅存储，不提取 |

---

## 7. 图数据库

基于 Apache AGE，支持 Cypher 查询。

### 7.1 节点和关系类型

```python
from neuromemory.models.graph import NodeType, EdgeType

# 内置节点类型
NodeType.USER      # 用户
NodeType.MEMORY    # 记忆
NodeType.TOPIC     # 主题
NodeType.ENTITY    # 实体

# 内置关系类型
EdgeType.HAS_MEMORY     # 拥有记忆
EdgeType.RELATED_TO     # 相关
EdgeType.INTERESTED_IN  # 感兴趣
EdgeType.MENTIONED_IN   # 被提及
```

### 7.2 节点 CRUD

```python
# 创建节点
node = await nm.graph.create_node(
    NodeType.USER, "alice",
    properties={"name": "Alice", "age": 30},
    user_id="alice",
)

# 获取节点
node = await nm.graph.get_node("alice", NodeType.USER, "alice")

# 更新节点
await nm.graph.update_node("alice", NodeType.USER, "alice", {"age": 31})

# 删除节点（同时删除相关边）
await nm.graph.delete_node("alice", NodeType.USER, "alice")
```

### 7.3 关系 CRUD

```python
# 创建关系
edge = await nm.graph.create_edge(
    NodeType.USER, "alice",
    EdgeType.INTERESTED_IN,
    NodeType.TOPIC, "python",
    properties={"since": "2020"},
)

# 更新关系
await nm.graph.update_edge(
    NodeType.USER, "alice",
    EdgeType.INTERESTED_IN,
    NodeType.TOPIC, "python",
    {"level": "expert"},
)

# 删除关系
await nm.graph.delete_edge(
    NodeType.USER, "alice",
    EdgeType.INTERESTED_IN,
    NodeType.TOPIC, "python",
)
```

### 7.4 查询

```python
# 获取邻居
neighbors = await nm.graph.get_neighbors(
    "alice", NodeType.USER, "alice",
    edge_types=[EdgeType.INTERESTED_IN],
    direction="out",
    limit=20,
)

# 查找路径
path = await nm.graph.find_path(
    "alice", NodeType.USER, "alice",
    NodeType.TOPIC, "machine-learning",
    max_depth=3,
)

# 自定义 Cypher
results = await nm.graph.query(
    "MATCH (u:User)-[:INTERESTED_IN]->(t:Topic) RETURN t",
    params={},
)
```

---

## 8. 记忆提取

需要配置 `LLMProvider`。从对话中自动提取偏好、事实和事件。

### 8.1 基础用法

```python
from neuromemory import OpenAILLM

nm = NeuroMemory(
    database_url="...",
    embedding=SiliconFlowEmbedding(api_key="..."),
    llm=OpenAILLM(api_key="...", model="deepseek-chat"),
)

# 先录入对话
await nm.conversations.add_messages_batch(
    user_id="alice",
    messages=[
        {"role": "user", "content": "I just started working at Google as a ML engineer"},
        {"role": "assistant", "content": "That's great!"},
        {"role": "user", "content": "I prefer Python over Java for ML work"},
    ],
)

# 提取记忆
stats = await nm.extract_memories(user_id="alice")
```

### 8.2 提取结果

```python
{
    "preferences_extracted": 1,   # 存入 KV（key: "preferred_language", value: "Python"）
    "facts_extracted": 1,         # 存入 embeddings（content: "在 Google 担任 ML 工程师"）
    "episodes_extracted": 0,
    "messages_processed": 3,
}
```

---

## 9. 时间查询

### 9.1 时间范围查询

```python
from datetime import datetime, timezone

result = await nm.get_memories_by_time_range(
    user_id="alice",
    start_time=datetime(2026, 1, 1, tzinfo=timezone.utc),
    end_time=datetime(2026, 1, 31, 23, 59, 59, tzinfo=timezone.utc),
    memory_type="fact",
    limit=50,
)
```

### 9.2 最近记忆

```python
memories = await nm.get_recent_memories(
    user_id="alice",
    days=7,
    memory_types=["fact", "episodic"],
    limit=50,
)
```

### 9.3 时间线统计

```python
from datetime import date

stats = await nm.get_memory_timeline(
    user_id="alice",
    start_date=date(2026, 1, 1),
    end_date=date(2026, 1, 31),
    granularity="day",  # day, week, month
)
```

---

## 10. 错误处理

```python
try:
    await nm.add_memory(user_id="alice", content="test")
except Exception as e:
    # 数据库连接错误、Embedding API 错误等
    print(f"Error: {e}")
```

常见错误：

| 错误 | 原因 | 解决 |
|------|------|------|
| `ConnectionRefusedError` | PostgreSQL 未启动 | 启动 Docker 容器 |
| `ValueError: Storage not configured` | 未配置 S3Storage | 传入 storage 参数 |
| `ValueError: LLM not configured` | 未配置 LLMProvider | 传入 llm 参数 |
| `httpx.HTTPStatusError` | Embedding API 错误 | 检查 API Key |

---

## 11. 自定义 Provider

### 11.1 自定义 Embedding

```python
from neuromemory.providers.embedding import EmbeddingProvider

class MyEmbedding(EmbeddingProvider):
    @property
    def dims(self) -> int:
        return 768

    async def embed(self, text: str) -> list[float]:
        # 你的实现
        return await my_service.embed(text)

nm = NeuroMemory(database_url="...", embedding=MyEmbedding())
```

### 11.2 自定义 LLM

```python
from neuromemory.providers.llm import LLMProvider

class MyLLM(LLMProvider):
    async def chat(self, messages, temperature=0.7, max_tokens=1024):
        # 你的实现
        return await my_llm.complete(messages)

nm = NeuroMemory(database_url="...", embedding=..., llm=MyLLM())
```

### 11.3 自定义 Storage

```python
from neuromemory.storage.base import ObjectStorage

class MyStorage(ObjectStorage):
    async def upload(self, prefix, filename, data, content_type):
        # 你的实现
        return f"{prefix}/{filename}"

    async def download(self, object_key):
        ...

    async def delete(self, object_key):
        ...

nm = NeuroMemory(database_url="...", embedding=..., storage=MyStorage())
```

---

**文档维护**: 本文档随代码同步更新。如有问题，请提交 Issue。
